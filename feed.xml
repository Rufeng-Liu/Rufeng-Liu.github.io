<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://rufeng-liu.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://rufeng-liu.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-08-28T15:43:27+00:00</updated><id>https://rufeng-liu.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Sampling Weights</title><link href="https://rufeng-liu.github.io/blog/2024/Sampling-Weights/" rel="alternate" type="text/html" title="Sampling Weights"/><published>2024-07-16T00:00:00+00:00</published><updated>2024-07-16T00:00:00+00:00</updated><id>https://rufeng-liu.github.io/blog/2024/Sampling-Weights</id><content type="html" xml:base="https://rufeng-liu.github.io/blog/2024/Sampling-Weights/"><![CDATA[<h2 id="sampling-weights">Sampling Weights</h2> <p>Construct a base weight for each sampled unit, the reciprocal of its probability of selection into the sample, to correct for their unequal probabilities of selection, e.g, \(w_i=\frac{1}{p_i}\).</p> <p>For multi-stage designs, the base weights must reflect the probabilities of selection at each stage, e.g, \(p_{ij}=p_i\times p_{j(i)}\). Then, base weight \(w_{ij,b}=\frac{1}{p_{ij}}\).</p> <p>The weight for non-response \(w_{ij,nr}\), and the weight for non-coverage is \(w_{ij,nc}\), will be explained later. The overall weight is \(w_{ij}=w_{ij,b}\times w_{ij,nr} \times w_{ij,nc}\).</p> <p>Some units have duplicates on the frame, then increased probability of selection of such units can be compensated. Suppose the \(i\)-th sampled unit has a probability of selections denoted by \(p_{i1},\ldots,p_{ik}\), the adjusted probability of selection of the sampled unit is \(p_i=1-(1-p_{i1})(1-p_{i2})\cdots(1-p_{ik})\), then \(w_i=\frac{1}{p_i}\).</p> <h3 id="for-non-response">For non-response</h3> <p>In a survey, participants may provide no data at all (<code class="language-plaintext highlighter-rouge">total non-response</code>) or only partial data (<code class="language-plaintext highlighter-rouge">item non-response</code>). If there are any systematic differences between the respondents and non-respondents, then naive estimates based solely on the respondents will be biased. The size of the non-response bias for a sample mean, for instance, is a function of two factors: (1) the proportion of the population that does not respond, (2) the size of the difference in population means between respondent and nonrespondent groups. Reducing the bias due to non-response therefore requires that either the non-response rate be small, or that there are small differences between responding and non-responding households and persons.</p> <p>For <code class="language-plaintext highlighter-rouge">total non-response</code>, there are three basic procedures for compensation:</p> <ol> <li>Non-response adjustment of the weights.</li> <li>Drawing a larger sample than needed and creating a reserve sample from which replacements are selected in case of non-response.</li> <li>Substitution, the process of replacing a non-responding participant with another participant that was not sampled which is in close proximity to the non-responding participant with respect to the characteristic of interest.</li> </ol> <h4 id="non-response-adjustment-of-sample-weights">Non-response adjustment of sample weights</h4> <p>The adjustment transfers the base weights of all eligible non-responding sampled units to the responding units.</p> <ol> <li>Apply the initial weights;</li> <li>Partition the sample into subgroups and compute weighted response rates for each subgroup;</li> <li>Use the reciprocal of the subgroup response rates for non-response adjustments;</li> <li>Calculate the non-response adjusted weight for the \(i\)-th unit as \(w_i=w_{1i}\times w_{2i}\), where \(w_{1i}\) is the initial weight and \(w_{2i}\) is the non-response adjustment weight.</li> </ol> <h3 id="for-non-coverage">For non-coverage</h3> <p><code class="language-plaintext highlighter-rouge">Non-coverage</code> refers to the failure of the sampling frame to cover all of the target population and thus some sampling units have no probability of selection into the sample selected for the survey.</p> <p>Several procedures for handling the problem of non-coverage:</p> <ol> <li>Improved field procedures such as the use of multiple frames and improved listing procedures;</li> <li>Compensating for the non-coverage through a statistical adjustment of the weights.</li> </ol> <h2 id="nhanes">NHANES</h2> <p><a href="https://wwwn.cdc.gov/nchs/nhanes/tutorials/weighting.aspx">Weighting in NHANES</a>.</p>]]></content><author><name></name></author><category term="sample"/><category term="methods"/><summary type="html"><![CDATA[Sampling weights]]></summary></entry><entry><title type="html">Horseshoe estimator</title><link href="https://rufeng-liu.github.io/blog/2024/Horseshoe-Estimator/" rel="alternate" type="text/html" title="Horseshoe estimator"/><published>2024-07-09T00:00:00+00:00</published><updated>2024-07-09T00:00:00+00:00</updated><id>https://rufeng-liu.github.io/blog/2024/Horseshoe-Estimator</id><content type="html" xml:base="https://rufeng-liu.github.io/blog/2024/Horseshoe-Estimator/"><![CDATA[<p>Introduction to Horseshoe estimator/prior, comparison versus other priors like spike-and-slab.</p> <h2 id="horseshoe">Horseshoe</h2> <p>Citation <d-cite key="carvalho2010horseshoe"></d-cite></p> <h2 id="properties">Properties</h2> <h2 id="comparison">Comparison</h2> <hr/>]]></content><author><name></name></author><category term="Bayesian-model/variable-selection"/><category term="Horseshoe"/><category term="sparsity"/><summary type="html"><![CDATA[Horseshoe for sparsity]]></summary></entry><entry><title type="html">Jackknife, Bootstrap and Bayesian Bootstrap</title><link href="https://rufeng-liu.github.io/blog/2024/Jackknife-Bootstrap-BayesianBootstrap/" rel="alternate" type="text/html" title="Jackknife, Bootstrap and Bayesian Bootstrap"/><published>2024-07-06T00:00:00+00:00</published><updated>2024-07-06T00:00:00+00:00</updated><id>https://rufeng-liu.github.io/blog/2024/Jackknife-Bootstrap-BayesianBootstrap</id><content type="html" xml:base="https://rufeng-liu.github.io/blog/2024/Jackknife-Bootstrap-BayesianBootstrap/"><![CDATA[<p>Ways of resampling, comparison of Jackknife, Bootstrap and Bayesian Bootstrap.</p> <h2 id="jackknife">Jackknife</h2> <p>Citation <d-cite key="miller1974jackknife"></d-cite></p> <p>Given a sample of size \(n\), a <a href="https://en.wikipedia.org/wiki/Jackknife_resampling">jackknife estimator</a> can be built by aggregating the parameter estimates from each subsample of size \((n-1)\) obtained by omitting one observation.</p> <p>Useful for bias and variance estimation, a linear approximation of the bootstrap.</p> <h2 id="bootstrap">Bootstrap</h2> <p>Citation <d-cite key="efron1992bootstrap"></d-cite></p> <p>The <a href="https://en.wikipedia.org/wiki/Bootstrapping_(statistics)">bootstrap</a> works by treating inference of the true probability distribution \(J\), given the original data, as being analogous to an inference of the empirical distribution \(\hat{J}\), given the resampled data (using random sampling with replacement). The accuracy of inferences regarding \(\hat{J}\) using the resampled data can be assessed because we know \(\hat{J}\). If \(\hat{J}\) is a reasonable approximation to \(J\), then the quality of inference on \(J\) can in turn be inferred.</p> <p>Suppose we have a sample of size \(n\), \(x_1, \ldots, x_n\), i.i.d. from a random variable/vector \(X\). A statistic \(\hat{\phi}\) is chosen to estimate a parameter \(\phi\) of the distribution of \(X\). The bootstrap distribution of \(\hat{\phi}\) is generated by taking repeated bootstrap replications from \(x_1, \ldots, x_n\). Each replication from \(x_1, \ldots, x_n\) is a random sample of size \(n\) with replacement, and each replication of \(\hat{\phi}\) is the value of \(\hat{\phi}\) calculated on the boostrap replicated sample. The bootstrapped distribution of \(\hat{\phi}\) is generated by considering all possible bootstrap replications of \(\hat{\phi}\).</p> <p>A generalization of the jackknife, useful in estimating the properties of an estimand or constructing hypothesis tests.</p> <p>Pros: straightforward, can be applied to complex sampling designs, control and check the stability.</p> <p>Cons: rely on assumptions (e.g. independence of samples or large enough of a sample size), time-consuming, lead to inconsistency with finite-sample.</p> <h2 id="bayesian-bootstrap">Bayesian Bootstrap</h2> <p>Citation <d-cite key="rubin1981bayesian"></d-cite></p> <p>The <a href="https://en.wikipedia.org/wiki/Bootstrapping_(statistics)#Bayesian_bootstrap">Bayesian bootstrap</a> is analogous to the bootstrap.</p> <p>Each Bayesian bootstrap replication generates a posterior probability for each \(x_i\), where values of \(X\) that are not observed have zero posterior probability, just as they have zero probability under the sample cdf. The posterior probability for each \(x_i\) is centered at \(\frac{1}{n}\) but has variability. The way of generating is like drawing from a \(n-1\) variate Dirichlet distribution with parameter vector \((1, \ldots, 1)\). Specifically, one Bayesian bootstrap replication is generated by drawing \((n - 1)\) uniform \((0, 1)\) random variates \(u_1, \ldots, u_{n-1}\), ordering them, and calculating the gaps \(g_i = u_{(i)}-u_{(i-l)}, i = 1, \ldots, n-1\) where \(u_{(0)} = 0\) and \(u_{(n)} = 1\). Then \(g = (g_1, \ldots, g_n)\) is the vector of probabilities to attach to the data values \(x_1, \ldots, x_n\) in that Bayesian bootstrap replication. Considering all Bayesian bootstrap replications gives the Bayesian bootstrap distribution of the distribution of \(X\) and thus of any parameter of this distribution.</p> <p>The interpretations of the resulting distributions will be different because the Bayesian bootstrap simulates the posterior distribution of the parameter \(\phi\), whereas the bootstrap simulates the estimated sampling distribution of a statistic \(\hat{\phi}\) estimating \(\phi\). The Bayesian bootstrap has an inherent advantage over the bootstrap with respect to the resulting inferences about parameters: the Bayesian bootstrap generates likelihood statements about parameters rather than frequency statements about statistics under assumed values for parameters.</p> <h2 id="bayesian-infinitesimal-jackknife">Bayesian infinitesimal jackknife</h2> <p>The <a href="https://rgiordan.github.io/posts/2020-08-09-bayes_ij.html">Bayesian (first-order) infinitesimal jackknife</a> is introduced by <a href="https://statistics.berkeley.edu/people/ryan-giordano-0">Ryan Giordano</a>.</p> <hr/>]]></content><author><name></name></author><category term="Resampling"/><summary type="html"><![CDATA[Bootstrap]]></summary></entry><entry><title type="html">Variational Inference</title><link href="https://rufeng-liu.github.io/blog/2024/Variational-Inference/" rel="alternate" type="text/html" title="Variational Inference"/><published>2024-06-28T00:00:00+00:00</published><updated>2024-06-28T00:00:00+00:00</updated><id>https://rufeng-liu.github.io/blog/2024/Variational-Inference</id><content type="html" xml:base="https://rufeng-liu.github.io/blog/2024/Variational-Inference/"><![CDATA[<p>Use optimization rather than use sampling. First posit a family of densities, then to find a member of that family which is close to the target density. Use exponential family as an example.</p> <h2 id="exponential-families">Exponential families</h2> <p><a href="https://en.wikipedia.org/wiki/Exponential_family">Exponential families</a> include <a href="https://en.wikipedia.org/wiki/Normal_distribution">normal</a>, <a href="https://en.wikipedia.org/wiki/Log-normal_distribution">log-normal</a>, <a href="https://en.wikipedia.org/wiki/Exponential_distribution">exponential</a>, <a href="https://en.wikipedia.org/wiki/Inverse_Gaussian_distribution">inverse Gaussian</a>, <a href="https://en.wikipedia.org/wiki/Gamma_distribution">gamma</a>, <a href="https://en.wikipedia.org/wiki/Chi-squared_distribution">chi-squared</a>, <a href="https://en.wikipedia.org/wiki/Beta_distribution">beta</a>, <a href="https://en.wikipedia.org/wiki/Dirichlet_distribution">Dirichlet</a>, <a href="https://en.wikipedia.org/wiki/Bernoulli_distribution">Bernoulli</a>, <a href="https://en.wikipedia.org/wiki/Categorical_distribution">categorical</a>, <a href="https://en.wikipedia.org/wiki/Poisson_distribution">Poisson</a>, <a href="https://en.wikipedia.org/wiki/Wishart_distribution">Wishart</a>, <a href="https://en.wikipedia.org/wiki/Inverse-Wishart_distribution">inverse Wishart</a>, <a href="https://en.wikipedia.org/wiki/Geometric_distribution">geometric</a>, <a href="https://en.wikipedia.org/wiki/Binomial_distribution">binomial</a>(with fixed number of trials), <a href="https://en.wikipedia.org/wiki/Multinomial_distribution">multinomial</a>(with fixed number of trials), <a href="https://en.wikipedia.org/wiki/Negative_binomial_distribution">negative binomial</a>(with fixed number of failures), <a href="https://en.wikipedia.org/wiki/Weibull_distribution">Weibull</a>(with fixed shape parameter)…</p> <p>For variable \(\boldsymbol{x}=(x_1,\ldots,x_k)^{T}\), a family of distributions with paramter \(\boldsymbol{\theta}\equiv (\theta_1,\ldots,\theta_s)^{T}\) is said to belong to an exponential family if the p.d.f (or p.m.f) can be written as</p> \[f_X(\boldsymbol{X}\mid\boldsymbol{\theta})=h(\boldsymbol{x})\text{exp}\left(\sum_{i=1}^{s} \eta_{i}(\boldsymbol{\theta})T_i(\boldsymbol{x})-A(\boldsymbol{\theta})\right)\] <p>or campactly</p> \[f_X(\boldsymbol{X}\mid\boldsymbol{\theta})=h(\boldsymbol{x})\text{exp}\left(\boldsymbol{\eta}(\boldsymbol{\theta})\cdot T(\boldsymbol{x})-A(\boldsymbol{\theta})\right)\] <p>The dimensions \(k\) of the random variable need not match the dimension \(d\) of the parameter vector, nor (in the case of a curved exponential function) the dimension \(s\) of the natural parameter \(\boldsymbol{\eta}\) and sufficient statistic \(T(\boldsymbol{x})\) .</p> <h2 id="dirichlet-process-and-dirichlet-process-mixture">Dirichlet process and Dirichlet process mixture</h2> <p>Citation <d-cite key="ferguson1973bayesian"></d-cite></p> <p>A <code class="language-plaintext highlighter-rouge">Dirichlet process</code> \(G\) is parameterized by a centering measure \(G_0\) and a positive presicion/scaling parameter \(\alpha\), if for all natural numbers \(k\) and \(k\)-partitions \(\{B_1,\ldots,B_k\}\):</p> \[\left(G(B_1),\ldots,G(B_k)\right)\sim \text{Dir}\left(\alpha G_0(B_1),\ldots,\alpha G_0(B_k)\right).\] <p>Suppose \(N\) random variables \(\eta_n\) are independently drawn from \(G\):</p> \[\begin{aligned} G\mid G_0,\alpha &amp;\sim \text{DP}(G_0,\alpha)\\ \eta_n &amp;\sim G, \quad n\in\{1,\ldots,N\}. \end{aligned}\] <p>Conditioning on \(n − 1\) draws, the \(n\)th value is, with positive probability, exactly equal to one of those draws:</p> \[p(\cdot\mid \eta_1,\ldots,\eta_{n-1})\propto \alpha G_0(\cdot)+\sum_{i=1}^{n-1} \delta_{\eta_i}(\cdot).\] <p>Thus, the variables \(\{\eta_1,\ldots,\eta_{n−1}\}\) are randomly partitioned according to which variables are equal to the same value, with the distribution of the partition obtained from a Polya urn scheme.</p> <p>Let \(\{\eta^{*}_{1},\ldots,\eta^{*}_{\lvert \boldsymbol{c} \rvert }\}\) denote the distinct values of \(\{\eta_1,\ldots,\eta _{n-1}\}\), let \(\boldsymbol{c} = \{c_1,...,c_ {n−1}\}\) be assignment variables such that \(\eta_i = \eta^*_ {c_i}\), and let \(\lvert\boldsymbol{c}\rvert\) denote the number of cells in the partition. The distribution of \(\eta_n\) follows the urn distribution:</p> \[\eta_n = \begin{cases} \eta^*_i &amp; \text{with prob.} \frac{|\lbrace j:c_j=i \rbrace|}{n-1+\alpha} \\ \eta, \eta\sim G_0 &amp; \text{with prob.} \frac{\alpha}{n-1+\alpha}, \end{cases}\] <p>where</p> \[|\{j : c_ {j}=i\}|\] <p>is the number of times the value \(\eta^{*}_{i}\) occurs in \(\{\eta_{1},\ldots,\eta_{n−1}\}\).</p> <p>Given Dirichlet process \(G\), a DP mixtures are densities \(p(x)=\int p(x, \eta)d\eta\), or there can be non-i.i.d observations \(x_n\overset{ind}{\sim}p_{n,G}(x)=\int p(x;\eta)dG(\eta)\), in terms of \(N\) latent variables \(\eta_1,\ldots,\eta_N\), the model can be written as</p> \[x_n\mid\eta_n\overset{ind}{\sim}p_n(x_n;\eta_n), \quad \eta_n\mid G\overset{i.i.d}{\sim}G, \quad G\mid G_0,\alpha \sim \text{DP}(G_0,\alpha)\] <p>Given a sample \(\{x_1,\ldots,x_N\}\) from a DP mixture, the predictive density is</p> \[p(x\mid x_1,\ldots,x_N,\alpha,G_0)=\int p(x\mid \eta)p(\eta\mid x_1,\ldots,x_N,\alpha,G_0)d\eta\] <p>which one can use MCMC to achieve posterior draws, together with posterior distribution \(p(\eta\mid x_1,\ldots,x_N,\alpha,G_0)\).</p> <p>The <code class="language-plaintext highlighter-rouge">stick-breaking</code> representation <d-cite key="sethuraman1994constructive"></d-cite> is widely used. Consider two infinite collections of independent random variables, \(V_i\sim\text{Beta}(1,\alpha)\) and \(\eta^*_i\sim G_0\), for \(i=\{1,2,\ldots\}\). The stick-breaking representation of \(G\) is as follows:</p> \[G=\sum_{i=1}^{\infty} \pi_i(\boldsymbol{v})\delta_{\eta^*_i}, \quad \pi_i(\boldsymbol{v})=v_{i} \prod_{j=1}^{i-1}(1-v_j)\] <p>In the DP mixture, the vector \(\pi(\boldsymbol{v})\) comprises the infinite vector of mixing proportions and \(\{\eta^*_1,\eta^*_2,\ldots\}\) are the atoms representing the mixture components. Let \(Z_n\) be an assignment variable of the mixture component with which the data point \(x_n\) is associated. The data can be described as arising from the following process:</p> <ol> <li>Draw \(V_i\sim \text{Beta}(1,\alpha), \quad i=\{1,2,\ldots\}\)</li> <li>Draw \(\eta^*_i\mid G_0\sim G_0, \quad \quad i=\{1,2,\ldots\}\)</li> <li> <p>For the \(n\)th data point:</p> <p>(a) Draw \(Z_n\mid \{v_1,v_2,\ldots\}\sim \text{Mult}(\pi(\boldsymbol{v}))\); (b) Draw \(X_n\mid z_n\sim p(x_n\mid \eta^*_{z_n})\)</p> </li> </ol> <p>Restrict the DP mixtures that the observable data are drawn from an exponential family distribution, and where the base distribution for the DP is the corresponding conjugate prior.</p> <p>The distribution of \(X_n\) conditional on \(Z_n\) and \({\eta^*_1,\eta^*_2,\ldots}\) is:</p> \[p(x_n\mid z_n,\eta^*_1,\eta^*_2,\ldots)=\prod_{i=1}^{\infty} \left(h(x_n) \text{exp} \left\{ {\eta^* _i}^T x_n-a(\eta^*_i) \right\} \right)^{\mathbf{1}\lbrack z_n=i \rbrack}\] <p>where \(a(\eta^*_i)\) is the appropriate cumulant function and it is assumed for simplicity that \(x\) is the sufficient statistic for the natural parameter \(\eta\).</p> <p>The vector of sufficient statistics of the corresponding conjugate family is \(({\eta^* _i}^T, -a(\eta^*_i) )^T\). The base distribution is:</p> \[p(\eta^*\mid \lambda) = h(\eta^*) \text{exp}\left\{\lambda_1^T \eta^* + \lambda_2 (-a(\eta^*))-a(\lambda)\right\}\] <p>where the hyperparameter \(\lambda\) is decomposed, such that \(\lambda_1\) contains the first \(\dim(\eta^*)\) components and \(\lambda_2\) is a scalar.</p> <h2 id="inference">Inference</h2> <p>Citation <d-cite key="blei2017variational"></d-cite></p> <h3 id="gibbs-sampling">Gibbs sampling</h3> <p>Review of the collapsed Gibbs sampler and blocked Gibbs sampler for DP mixtures. Blocked Gibbs sampler outshines collapsed Gibbs sampler when \(G_0\) is not conjugate.</p> <h4 id="collapesd-gibbs-sampling">Collapesd Gibbs sampling</h4> <p>The <code class="language-plaintext highlighter-rouge">collapsed Gibbs sampler</code> for a DP mixture with conjugate base distribution integrates out the random measure \(G\) and distinct parameter values \(\{\eta^{*}_{1},\ldots,\eta^{*}_{\lvert \boldsymbol{c} \rvert }\}\). The Markov chain is thus defined only on the latent partition \(\boldsymbol{c} = \{c_1,...,c_ {N}\}\), where \(\lvert\boldsymbol{c}\rvert\) denote the number of cells in the partition. The algorithm iteratively samples each assignment variable \(C_n\), for \(n\in \{1,\ldots,N\}\), conditional on the other cells in the partition, \(\boldsymbol{c_{-n}}\). The assignment \(C_n\) can be one of \(\lvert \boldsymbol{c_{-n}}\rvert +1\) values: either the \(n\)th data point is in a cell with other data points, or in a cell by itself.</p> <p>Exchangeability implies that \(C_n\) has the following multinomial distribution:</p> \[p(c_n=k\mid \boldsymbol{x},\boldsymbol{c}_ {-n},\lambda,\alpha)\propto p(x_n\mid \boldsymbol{x}_ {-n}, \boldsymbol{c}_ {-n}, c_n=k, \lambda)p(c_n=k\mid \boldsymbol{c}_ {-n}, \alpha)\] <p>The first term is a ratio of normalizing constants of the posterior distribution of the \(k\)th parameter, one including and one excluding the \(n\)th data point:</p> \[p(x_n\mid \boldsymbol{x}_ {-n}, \boldsymbol{c}_ {-n}, c_n=k, \lambda)=\frac{\text{exp}\lbrace a(\lambda_1+\sum_{m\neq n} \mathbf{1} \lbrack c_m =k \rbrack x_m +x_n, \lambda_2 +\sum_{m\neq n} \mathbf{1} \lbrack c_m =k \rbrack +1)\rbrace}{\text{exp}\lbrace a(\lambda_1+\sum_{m\neq n} \mathbf{1} \lbrack c_m =k \rbrack x_m, \lambda_2 +\sum_{m\neq n} \mathbf{1} \lbrack c_m =k \rbrack)\rbrace}\] <p>The second term is given by the Polya urn scheme:</p> \[p(c_n=k\mid \boldsymbol{c}_ {-n}, \alpha) = \begin{cases} \vert\lbrace j:c_{-n,j}=k \rbrace\vert &amp; \text{if } k \text{ is an existing cell in the partition}\\ \alpha &amp; \text{if } k \text{ is a new cell in the partition} \end{cases}\] <p>where \(\vert\lbrace j:c_{-n,j}=k \rbrace\vert\) denotes the number of data points in the kth cell of the partition \(\boldsymbol{c}_{-n}\).</p> <p>After the chain has reached stationary distribution, \(B\) samples \(\lbrace \boldsymbol{c}_1, \dots, \boldsymbol{c}_B \rbrace\) are collected to approximate the posterior. The approximate predictive distribution is an average of the predictive distributions across the Monte Carlo samples:</p> \[p(x_{N+1}\mid x_1, \ldots, x_N,\alpha,\lambda)=\frac{1}{N} \sum_{b=1}^{B} p(x_{N+1}\mid \boldsymbol{c}_b,\boldsymbol{x},\alpha,\lambda)\] <p>For a given sample, that distribution is:</p> \[p(x_{N+1}\mid \boldsymbol{c}_ {b},\boldsymbol{x},\alpha,\lambda) = \sum_{k=1}^{\vert \boldsymbol{c}_ b \vert+1} p(c_{N+1}=k \mid \boldsymbol{c}_ b,\alpha)p(x_{N+1}\mid \boldsymbol{c}_ b, \boldsymbol{x}, c_{N+1}=k, \lambda)\] <h4 id="blocked-gibbs-sampling">Blocked Gibbs sampling</h4> <p>Ishwaran and James <d-cite key="ishwaran2001gibbs"></d-cite> developed a <code class="language-plaintext highlighter-rouge">blocked Gibbs sampling</code> algorithm based on the <code class="language-plaintext highlighter-rouge">stick-breaking</code> representation. A truncated Dirichlet process (TDP) is defined by setting \(v_{K-1}=1\) and \(\pi_i(\boldsymbol{v})=0\) for \(i\geq K\), and showed that the truncated process closely approximates a true Dirichlet process when the truncation level is chosen large relative to the number of data points.</p> <p>In the TDP mixture, the state of the Markov chain consists of the beta variables \(\boldsymbol{V}=\{V_1,\ldots,V_{K-1}\}\), the mixture component parameters \(\boldsymbol{\eta}^*=\{\eta_1^*,\ldots,\eta_K^*\}\), and the indicator variables \(\boldsymbol{Z}=\{Z_1,\ldots,Z_N\}\). The blocked Gibbs sampler iterates between the following three steps:</p> <ol> <li> <p>For \(n\in\{1,\ldots,N\}\), independently sample \(Z_n\) from:</p> \[p(z_n=k\mid \boldsymbol{v},\boldsymbol{\eta}^*,\boldsymbol{x}) = \pi_{k}(\boldsymbol{v})p(x_n\mid \eta^* _k)\] </li> <li> <p>For \(k\in\{1,\ldots,K\}\), independently sample \(V_k\) from \(\text{Beta}(\gamma_{k,1},\gamma_{k,2})\), where:</p> \[\begin{aligned} \gamma_{k,1} &amp; = 1 + \sum_{n=1}^{N} \mathbf{1}\lbrack z_n=k \rbrack \\ \gamma_{k,2} &amp; = \alpha + \sum_{i=k+1}^{K} \sum_{n=1}^{N} \mathbf{1}\lbrack z_n=i \rbrack \end{aligned}\] </li> <li> <p>For \(k\in\{1,\ldots,K\}\), independently sample \(\eta_k^*\) from \(p(\eta^ *_k \mid \tau_k)\). This distribution is in the same family as the base distribution, with parameters:</p> \[\begin{aligned} \tau_{k,1} &amp; = \lambda_1 + \sum_{i\neq n} \mathbf{1}\lbrack z_i=k \rbrack x_i\\ \tau_{k,2} &amp; = \lambda_2 + \sum_{i\neq n} \mathbf{1}\lbrack z_i=k \rbrack \end{aligned}\] <p>where as before, the hyperparameter \(\lambda\) of the conjugate exponential family is decomposeed, such that \(\lambda_1\) contains the first \(\dim(\eta^*)\) components and \(\lambda_2\) is a scalar.</p> </li> </ol> <p>After the chain has reached its stationary distribution, \(B\) samples are collected and an approximate predictive distribution can be constructed. For a particular sample:</p> \[p(x_{N+1}\mid \boldsymbol{z},\boldsymbol{x},\alpha,\lambda) = \sum_{k=1}^{K} \mathrm{E}\lbrack \pi_{i}(\boldsymbol{V} \mid \gamma_1,\ldots,\gamma_k) \rbrack p(x_{N+1}\mid \tau_k)\] <h3 id="variational-inference">Variational inference</h3> <p>Consider a model with hyperparameters \(\theta\), latent variables \(\boldsymbol{W}=\lbrace W_1,\ldots,W_M\rbrace\), and observations \(\boldsymbol{x}=\lbrace x_1,\ldots,x_N\rbrace\). The posterior distribution of the latent variables \(p(\boldsymbol{w}\mid\boldsymbol{x},\theta)=\frac{p(\boldsymbol{w},\boldsymbol{x}\mid \theta)}{p(\boldsymbol{x}\mid \theta)}=\text{exp}\lbrace\log p(\boldsymbol{w},\boldsymbol{x}\mid \theta)-\log p(\boldsymbol{x}\mid \theta)\rbrace\) is difficult to compute, because the latent variables become dependent when conditioning on observed data, then \(\log p(\boldsymbol{x}\mid \theta)=\log \int p(\boldsymbol{w},\boldsymbol{x}\mid \theta)d\boldsymbol{w}\) is hard to compute.</p> <p>A class of variational methods known as <code class="language-plaintext highlighter-rouge">mean-field methods</code> are based on optimizing Kullback-Leibler (KL) divergence with respect to a so-called variational distribution. Let \(q_{\nu}(\boldsymbol{w})\) be a family of distributions indexed by a variational parameter \(\nu\), the aim is to minimize the KL divergence between \(q_{\nu}(\boldsymbol{w})\) and \(p(\boldsymbol{w}\mid\boldsymbol{x},\theta)\):</p> \[\mathbf{D}(q_{\nu}(\boldsymbol{w}) \Vert p(\boldsymbol{w}\mid\boldsymbol{x},\theta)) = \mathbf{E}_ {q} \lbrack \log q_{\nu}(\boldsymbol{W}) \rbrack - \mathbf{E}_ {q} \lbrack \log p(\boldsymbol{W},\boldsymbol{x}\mid\theta) \rbrack + \log p(\boldsymbol{x}\mid \theta)\] <p>As the marginal probability does not depend on the variational parameters, it can be ignored in the optimization. To minimize the KL divergence can be cast alternatively as to compute the maximization of a lower bound on the log marginal likelihood:</p> \[\log p(\boldsymbol{x}\mid \theta) \geq \mathbf{E}_ {q} \lbrack \log p(\boldsymbol{W},\boldsymbol{x}\mid\theta) \rbrack - \mathbf{E}_ {q} \lbrack \log q_{\nu}(\boldsymbol{W}) \rbrack\] <p>To constructe the family \(q_{\nu}(\boldsymbol{w})\), it is in need to break some of dependencies between latent variables which make the true posterior difficult to compute.</p> <h4 id="mean-field-variational-inference-in-exponential-families">Mean field variational inference in exponential families</h4> <p>For each latent variable, assume that the conditional distribution is a member of the exponential family:</p> \[p(w_{i}\mid \boldsymbol{w}_ {-i},\boldsymbol{x},\theta)=h(w_{i})\text{exp} \lbrace {g_{i}(\boldsymbol{w}_ {-i},\boldsymbol{x},\theta)}^T w_{i} - a(g_{i}(\boldsymbol{w}_ {-i},\boldsymbol{x},\theta)) \rbrace\] <p>where \(g_{i}(\boldsymbol{w}_ {-i},\boldsymbol{x},\theta)\) is the natural parameter for \({w}_{i}\) when conditioning on the remaining latent variables and the observations.</p> <p>Consider the following family of distributions as mean field variational approximations:</p> \[q_{\boldsymbol{\nu}}(\boldsymbol{w})=\prod_{i=1}^{M} q_{\nu_i}(w_i) =\prod_{i=1}^{M} \text{exp} \lbrace \nu_{i}^T w_{i} - a(w_{i}) \rbrace\] <p>where \(\boldsymbol{\nu}=\lbrace \nu_1,\ldots, \nu_M \rbrace\) are variational parameters and each distribution is in the exponential family. Then it is shown that the optimization of KL divergence with respect to a single variational parameter \(\nu_{i}\) is achieved by computing the following expectation:</p> \[\nu_{i} = \mathbf{E}_ {q} \lbrack g_{i}(\boldsymbol{W}_ {-i},\boldsymbol{x},\theta) \rbrack\] <p>In a coordinate ascent algorithm, the bound with respect to each \(\nu_i\) is iteratively maximized, holding the other variational parameters fixed.</p> <p>Using the chain rule, the bound can be rewriten:</p> \[\log p(\boldsymbol{x}\mid \theta) \geq \log p(\boldsymbol{x}\mid \theta) + \sum_{m=1}^{M} \mathbf{E}_ {q} \lbrack \log p(W_m \mid W_1,\ldots, W_{m-1}, \boldsymbol{x},\theta) \rbrack - \sum_{m=1}^{M} \mathbf{E}_ {q} \lbrack \log q_{\nu_m}(W_m) \rbrack\] <p>To optimize with respect to \(\nu_{i}\), the part depend on \(\nu_{i}\) is :</p> \[l_{i}= \mathbf{E}_ {q} \lbrack \log p(W_i \mid \boldsymbol{W}_ {-i}, \boldsymbol{x},\theta) \rbrack - \mathbf{E}_ {q} \lbrack \log q_{\nu_i}(W_i) \rbrack\] <p>Given that the variational distribution \(q_{\nu_i}(w_i)\) is in the exponential family:</p> \[q_{\nu_i}(w_i)=h(w_i)\text{exp}\lbrace \nu_i^T w_i - a(\nu_i) \rbrace\] <p>as in the exponential family \(\mathbf{E}_ {q} \lbrack W_i\rbrack = a'(\nu_i)\), it is easy to see,</p> \[\begin{aligned} l_{i} &amp;= \mathbf{E}_ {q} \lbrack \log p(W_i \mid \boldsymbol{W}_ {-i}, \boldsymbol{x},\theta) - \log h(W_i) - \nu_i^T w_i + a(\nu_i) \rbrack \\ &amp;= \mathbf{E}_ {q} \lbrack \log p(W_i \mid \boldsymbol{W}_ {-i}, \boldsymbol{x},\theta) \rbrack - \mathbf{E}_ {q} \lbrack \log h(W_i) \rbrack - \nu_i^T a'(\nu_i) + a(\nu_i) \end{aligned}\] <p>The derivative with respect to \(\nu_i\) is:</p> \[\frac{\partial l_{i}}{\partial \nu_i} = \frac{\partial}{\partial \nu_i} ( \mathbf{E}_ {q} \lbrack \log p(W_i \mid \boldsymbol{W}_ {-i}, \boldsymbol{x},\theta) \rbrack - \mathbf{E}_ {q} \lbrack \log h(W_i) \rbrack ) - \nu_i^T a''(\nu_i)\] <p>let partial derivative equals \(0\), the optimal \(\nu_i\) satisfies:</p> \[\nu_i = \lbrack a''(\nu_i) \rbrack ^{-1} ( \frac{\partial}{\partial \nu_i}\mathbf{E}_ {q} \lbrack \log p(W_i \mid \boldsymbol{W}_ {-i}, \boldsymbol{x},\theta) \rbrack - \frac{\partial}{\partial \nu_i}\mathbf{E}_ {q} \lbrack \log h(W_i) \rbrack )\] <p>as we assumed that the conditional distribution is a member of the exponential family:</p> \[p(w_{i}\mid \boldsymbol{w}_ {-i},\boldsymbol{x},\theta)=h(w_{i})\text{exp} \lbrace {g_{i}(\boldsymbol{w}_ {-i},\boldsymbol{x},\theta)}^T w_{i} - a(g_{i}(\boldsymbol{w}_ {-i},\boldsymbol{x},\theta)) \rbrace\] <p>where \(g_{i}(\boldsymbol{w}_ {-i},\boldsymbol{x},\theta)\) is the natural parameter for \(w_{i}\) when conditioning on the remaining latent variables and the observations. We have the expected log probability of \(W_i\) and its first derivative:</p> \[\begin{aligned} \mathbf{E}_ {q} \lbrack \log p(W_i \mid \boldsymbol{W}_ {-i}, \boldsymbol{x},\theta) \rbrack &amp; = \mathbf{E}_ {q} \lbrack \log h(W_{i})\rbrack + \mathbf{E}_ {q} \lbrack g_{i}(\boldsymbol{W}_ {-i},\boldsymbol{x},\theta)\rbrack ^T a'(\nu_i) - \mathbf{E}_ {q} \lbrack a(g_{i}(\boldsymbol{W}_ {-i},\boldsymbol{x},\theta)) \rbrack \\ \frac{\partial}{\partial \nu_i} \mathbf{E}_ {q} \lbrack \log p(W_i \mid \boldsymbol{W}_ {-i}, \boldsymbol{x},\theta) \rbrack &amp; = \frac{\partial}{\partial \nu_i} \mathbf{E}_ {q} \lbrack \log h(W_{i})\rbrack + \mathbf{E}_ {q} \lbrack g_{i}(\boldsymbol{W}_ {-i},\boldsymbol{x},\theta)\rbrack^T a''(\nu_i) \end{aligned}\] <p>put first derivative in the equation of the optimal \(\nu_i\):</p> \[\nu_{i} = \mathbf{E}_ {q} \lbrack g_{i}(\boldsymbol{W}_ {-i},\boldsymbol{x},\theta) \rbrack\] <h4 id="coordinate-ascent-algorithm-for-dp-mixtures">Coordinate ascent algorithm for DP mixtures</h4> <p>Based on the stick-breaking representation, the latent variables are the stick lengths, the atoms, and the cluster assignments: \(\boldsymbol{W}=\{\boldsymbol{V},\boldsymbol{\eta}^*,\boldsymbol{Z}\}\), with the scaling parameter and the parameter of the conjugate base distribution \(\theta = \{\alpha,\lambda\}\) as the hyperparameters. The <code class="language-plaintext highlighter-rouge">variational bound</code> on the log marginal probability of the data:</p> \[\begin{aligned} \log p(\boldsymbol{x}\mid \alpha,\lambda) &amp; \geq \mathbf{E}_ {q} \lbrack \log p(\boldsymbol{V},\boldsymbol{\eta}^*,\boldsymbol{Z},\boldsymbol{x}\mid \alpha,\lambda) \rbrack - \mathbf{E}_ {q} \lbrack \log q(\boldsymbol{V},\boldsymbol{\eta}^*,\boldsymbol{Z}) \rbrack \\ &amp; = \sum_{n=1}^{N} (\mathbf{E}_ {q} \lbrack \log p(x_n \mid Z_n) \rbrack + \mathbf{E}_ {q} \lbrack \log p(Z_n \mid \boldsymbol{V}) \rbrack ) + \mathbf{E}_ {q} \lbrack \log p(\boldsymbol{V} \mid \alpha) \rbrack + \mathbf{E}_ {q} \lbrack \log p(\boldsymbol{\eta}^* \mid \lambda) \rbrack - \mathbf{E}_ {q} \lbrack \log q(\boldsymbol{V},\boldsymbol{\eta}^*,\boldsymbol{Z}) \rbrack \end{aligned}\] <p>The variational distribution is truncated at level \(T\), the factorized family of variational distributions for mean field variational inference is:</p> \[q(\boldsymbol{V},\boldsymbol{\eta}^*,\boldsymbol{Z})= \prod_{t=1}^{T-1} q_{\gamma_{t}}(\nu_t) \prod_{t=1}^{T} q_{\tau_{t}}(\eta_t^*) \prod_{n=1}^{N} q_{\phi_{n}}(z_n)\] <p>where \(q_{\gamma_{t}}(\nu_t)\) are beta distributions, \(q_{\tau_{t}}(\eta_t^*)\) are exponential family distributions with natural parameters \(\tau_{t}\), and \(q_{\phi_{n}}(z_n)\) are multinomial distributions. The free variational parameters are:</p> \[\boldsymbol{\nu} = \{ \gamma_{1}, \ldots, \gamma_{T-1}, \tau_{1}, \ldots, \tau_{T}, \phi_{1}, \ldots, \phi_{N}\}\] <p>In the <code class="language-plaintext highlighter-rouge">variational bound</code> on the log marginal probability of the data, \(\mathbf{E}_ {q} \lbrack \log p(Z_n \mid \boldsymbol{V}) \rbrack\) is the only term not involving standard computations in the exponential family, which can be rewriten using indicator random variables:</p> \[\begin{aligned} \mathbf{E}_ {q} \lbrack \log p(Z_n \mid \boldsymbol{V}) \rbrack &amp;= \mathbf{E}_ {q} \lbrack \log (\prod_{i=1}^{\infty} (1-V_i)^{\mathbf{1}\lbrack Z_n&gt;i \rbrack} V_{i}^{\mathbf{1}\lbrack Z_n=i \rbrack} ) \rbrack \\ &amp; = \prod_{i=1}^{\infty} q(z_n&gt;i) \mathbf{E}_ {q} \lbrack \log (1-V_i) \rbrack + q(z_n=i) \mathbf{E}_ {q} \lbrack \log V_i \rbrack \end{aligned}\] <p>Truncated at \(t=T\)</p> \[\mathbf{E}_ {q} \lbrack \log p(Z_n \mid \boldsymbol{V}) \rbrack = \prod_{i=1}^{T} q(z_n&gt;i) \mathbf{E}_ {q} \lbrack \log (1-V_i) \rbrack + q(z_n=i) \mathbf{E}_ {q} \lbrack \log V_i \rbrack\] <p>where</p> \[\begin{aligned} q(z_n=i) &amp;= \phi_{n,i} \\ q(z_n&gt;i) &amp;= \sum_{j=i+1}^{T} \phi_{n,j} \\ \mathbf{E}_ {q} \lbrack \log V_i \rbrack &amp;= \Psi(\gamma_{i,1}) - \Psi(\gamma_{i,1}+\gamma_{i,2})\\ \mathbf{E}_ {q} \lbrack \log (1-V_i) \rbrack &amp;= \Psi(\gamma_{i,2}) - \Psi(\gamma_{i,1}+\gamma_{i,2}) \end{aligned}\] <p>The digamma function \(\Psi\) is derivative of the log-partition (\(A(\eta)\)) in the beta distribution.</p> <p>From the conclusion in last subsection \(\nu_{i} = \mathbf{E}_ {q} \lbrack g_{i}(\boldsymbol{W}_ {-i},\boldsymbol{x},\theta) \rbrack\), a mean-field coordinate ascent algorithm is derived:</p> \[\begin{aligned} \gamma_{t,1} &amp;= 1 + \sum_{n} \phi_{n,t} \\ \gamma_{t,2} &amp;= \alpha + \sum_{n} \sum_{j=t+1}^{T} \phi_{n,t} \\ \tau_{t,1} &amp;= \lambda_1 + \sum_{n} \phi_{n,t} x_n \\ \tau_{t,2} &amp;= \lambda_1 + \sum_{n} \phi_{n,t} \\ \phi_{n,t} &amp;\propto \text{exp}(S_t) \end{aligned}\] <p>for \(t \in\{1, \ldots,T\}, n\in \{1, \ldots, N\}\), where</p> \[S_t = \mathbf{E}_ {q} \lbrack \log V_t \rbrack + \sum_{i=1}^{t-1} \mathbf{E}_ {q} \lbrack \log (1-V_i) \rbrack + \mathbf{E}_ {q} \lbrack \eta_{t}^* \rbrack ^T X_n - \mathbf{E}_ {q} \lbrack a(\eta_{t}^*) \rbrack\] <p>Iterating these updates optimizes <code class="language-plaintext highlighter-rouge">variational bound</code> with respect to the variational parameters in the factorized family of variational distributions \(\mathbf{E}_ {q} \lbrack \log p(Z_n \mid \boldsymbol{V}) \rbrack\).</p> <p>The predictive distribution is:</p> \[p(x_{N+1}\mid \boldsymbol{x}, \alpha, \lambda) = \int (\sum_{t=1}^{\infty} \pi_t(\boldsymbol{V}) p(x_{N+1}\mid \eta_{t}^*)) d P(\boldsymbol{v},\boldsymbol{\eta}^*\mid \boldsymbol{x}, \alpha, \lambda)\] <p>it is approximated with a product of expectations:</p> \[p(x_{N+1}\mid \boldsymbol{x}, \alpha, \lambda) \approx \sum_{t=1}^{T} \mathbf{E}_ {q} \lbrack \pi_t(\boldsymbol{V}) \rbrack \mathbf{E}_ {q} \lbrack p(x_{N+1}\mid \eta_{t}^*) \rbrack\] <p>where \(q\) depends on \(\boldsymbol{x}, \alpha, \lambda\).</p> <h2 id="implementation">Implementation</h2> <p>Citation <d-cite key="blei2017variational"></d-cite> <d-cite key="blei2006variational"></d-cite></p> <hr/>]]></content><author><name></name></author><category term="Optimization"/><category term="Variational"/><category term="Dirichlet-process"/><summary type="html"><![CDATA[Variational Bayesian]]></summary></entry><entry><title type="html">Bayesian Model Selection via MCMC</title><link href="https://rufeng-liu.github.io/blog/2024/Bayesian-Model-Selection-via-MCMC/" rel="alternate" type="text/html" title="Bayesian Model Selection via MCMC"/><published>2024-06-24T00:00:00+00:00</published><updated>2024-06-24T00:00:00+00:00</updated><id>https://rufeng-liu.github.io/blog/2024/Bayesian-Model-Selection-via-MCMC</id><content type="html" xml:base="https://rufeng-liu.github.io/blog/2024/Bayesian-Model-Selection-via-MCMC/"><![CDATA[<h2 id="method">Method</h2> <p>Citation <d-cite key="carlin1995bayesian"></d-cite>.</p> <p>Choose between \(K\) models with corresponding parameter vector \(\boldsymbol{\theta}_j\), \(j=1,...K\).</p> <p>Let \(M\) be an integer-valued parameter that indexes the model, for model \(j\), we have a likelihood \(f(\boldsymbol{y}\mid \boldsymbol{\theta}_j,M=j)\) and a prior \(p(\boldsymbol{\theta}_j\mid M=j)\). Given \(M=j\), \(\boldsymbol{y}\) is independent of \(\{\boldsymbol{\theta_{i\neq j}}\}\). Assume that given the indicator \(M\), \(\boldsymbol{\theta}_j\) are independent of each other, we can complete the Bayesian model specification by choosing proper <code class="language-plaintext highlighter-rouge">pseudopriors</code> \(p(\boldsymbol{\theta}_j\mid M\neq j)\), which is a conveniently chosen linking density. Reason is shown below, let \(\boldsymbol{\theta}=\{\boldsymbol{\theta}_1,\ldots,\boldsymbol{\theta}_K\}\), \(p(\boldsymbol{y} \mid M=j)=\int f(\boldsymbol{y}\mid \boldsymbol{\theta},M=j)p(\boldsymbol{\theta}\mid M=j)d\boldsymbol{\theta}=\int f(\boldsymbol{y}\mid \boldsymbol{\theta}_{j},M=j)p(\boldsymbol{\theta}_{j}\mid M=j)d\boldsymbol{\theta}_j\) Given prior model probabilities \(\pi_{j}\equiv P(M=j)\) such that \(\sum_{j=1}^{K}\pi_{j}=1\), when \(M=j\), the joint distribution of \(\boldsymbol{y}\) and \(\boldsymbol{\theta}\) is</p> \[\begin{aligned} p(\boldsymbol{y},\boldsymbol{\theta},M=j) &amp; = f(\boldsymbol{y}\mid \boldsymbol{\theta},m=j)p(\boldsymbol{\theta}\mid M=j)p(M=j) \\ &amp; = f(\boldsymbol{y}\mid \boldsymbol{\theta}_j,m=j)p(\boldsymbol{\theta}\mid M=j)p(M=j) \\ &amp; = f(\boldsymbol{y}\mid \boldsymbol{\theta}_j,m=j) \left\{\prod_{i=1}^{K} p(\boldsymbol{\theta}_i\mid M=j)\right\} p(M=j)\\ &amp; = f(\boldsymbol{y}\mid \boldsymbol{\theta}_j,m=j) \left\{\prod_{i=1}^{K} p(\boldsymbol{\theta}_i\mid M=j)\right\} \pi_{j} \end{aligned}\] <p>To implement Gibbs sampler the full conditional distributions of each \(\boldsymbol{\theta}_j\) and \(M\). For \(\boldsymbol{\theta}_j\), when \(M=j\), we generate from the usual model \(j\) full conditional; when \(M\neq j\), we generate from the linking function (<code class="language-plaintext highlighter-rouge">pseudoprior</code>).</p> \[p(\boldsymbol{\theta}_j \mid \boldsymbol{\theta}_{i\neq j},M,\boldsymbol{y}) \propto \begin{cases} f(\boldsymbol{y}\mid \boldsymbol{\theta}_j,M=j)p(\boldsymbol{\theta}_j\mid M = j) &amp; M=j, \\ p(\boldsymbol{\theta}_j\mid M\neq j) &amp; M\neq j, \end{cases}\] <p>For discrete finite parameter \(M\):</p> \[p(M=j\mid \boldsymbol{\theta},\boldsymbol{y})=\frac{f(\boldsymbol{y}\mid \boldsymbol{\theta}_j,M=j)\prod_{i=1}^{K} p(\boldsymbol{\theta}_i\mid M=j) \pi_j}{\sum_{k=1}^{K} \left(f(\boldsymbol{y}\mid \boldsymbol{\theta}_k,M=k)\prod_{i=1}^{K} p(\boldsymbol{\theta}_i\mid M=k) \pi_k \right)}\] <p>The algorithm will produce samples from the correct joint posterior distribution. The ratio</p> \[\hat{p}(M=j\mid \boldsymbol{y})=\frac{\text{number of }M^{(g)}=j}{\text{total number of }M^{(g)}},\quad j=1,\ldots,K.\] <p>provides estimates that be used to compute the Bayes factor (ratio of the observed marginal densities for the two models)</p> \[B_{ji}=\frac{p(\boldsymbol{y}\mid M=j)}{p(\boldsymbol{y}\mid M=i)}\] <p>between any two of the models.</p> <hr/> <h2 id="implementation">Implementation</h2> <p>Citation <d-cite key="carlin1995bayesian"></d-cite>.</p> <p>Poor choices of the linking density (<code class="language-plaintext highlighter-rouge">pseudopriors</code>) \(p(\boldsymbol{\theta}_j\mid M\neq j)\) will make jumps between models extremely unlikely, so that the convergence of the Gibbs sampling may trapped to one model, which might not be the true one in fact. Good choices will produce \(\boldsymbol{\theta}_j^{(g)}\)-values that are consistent with the data, so that \(p(M=j\mid \boldsymbol{\theta},\boldsymbol{y})\) will still be reasonably large at the next \(M\) update step.</p> <p>If for a particular data set one of the \(p(M=j\mid \boldsymbol{y})\) is extremely large, the \(\pi_j\) may be adjusted to correct the imbalance during the early stage of the algorithm, so that the final value of \(B_{ji}\) reflect the true odds in favour of \(M=j\) suggested by the data.</p> <p>Key point: Use the data to help to select the <code class="language-plaintext highlighter-rouge">pseudopriors</code> but <code class="language-plaintext highlighter-rouge">not</code> the prior, match the <code class="language-plaintext highlighter-rouge">pseudopriors</code> as nearly as possible to the true model-specific posteriors.</p> <h3 id="example">Example</h3> <p>Citation <d-cite key="jauch2021mixture"></d-cite>.</p> <p>Let $I=(a,b)$ with $a,b\in \mathbb{R}\cup \lbrace -\infty,\infty \rbrace$. Suppose $f$ and $g$ are density functions with $\int_{I}f(x)dx=1$, $\int_{I}g(x)dx=1$, and $g&gt;0$ on $I$, with $F$ and $G$ be the corresponding distribution functions. For each $s\in I$, let $g^s$ denote the truncated density function with $g^s(x)=g(x)\mathbf{1}_ {(-\infty,s]}(x)/G(s)$ for $x\in I$. We say that $F$ is smaller than $G$ in the likelihood ratio order, denote $F\leq_{LR} G$, if $f/g$ is monotone non-increasing. It is shown that, $f/g$ is monotone non-increasing and locally absolutely continuous on $I$ if and only if there exists $\theta \in \lbrack 0,1 \rbrack$ and an absolutely continuous distribution function $U$ with density $u$, where $U(a+)=0$ and $U(b-)=1$ such that for $x\in I$,</p> \[f(x)=\theta g(x) + (1-\theta) \int_{a}^{b} g^{s}(x)u(s)ds\] <p>When this mixture representation exists, $\theta=\lim_{x\uparrow b} f(x)/g(x)$, if $\theta\in[0,1)$, $U$ is uniquely determined with $U(x)=\frac{G(x)}{1-\theta}\lbrace \frac{F(x)}{G(x)}-\frac{f(x)}{g(x)} \rbrace$, $x\in I$.</p> <p>If we have $I=\mathbb{R}$, densities $g$ and $u$ can be easily modeled using DP mixtures $\mathrm{DP}(P_0,\alpha)$ together with a Gaussian kernel $\phi_{\mu,\sigma^2}$,</p> \[\begin{aligned} g(\cdot\mid P_1) &amp;= \int_{\mathbb{R}\times \mathbb{R}^{+}} \phi_{\mu,\sigma^2}(\cdot) P_1(d\mu,d\sigma^2), \quad P_1\sim \mathrm{DP}(P_{1,0}, \alpha_1) \\ u(\cdot\mid P_2) &amp;= \int_{\mathbb{R}\times \mathbb{R}^{+}} \phi_{\mu,\sigma^2}(\cdot) P_2(d\mu,d\sigma^2), \quad P_2\sim \mathrm{DP}(P_{2,0}, \alpha_2) \end{aligned}\] <p>Under the truncated stick-breaking representation of DP,</p> \[P_k(\cdot)=\sum_{j=1}^{N} v_{k,j} \left\lbrace \prod_{l=1}^{j-1} (1-v_{k,l}) \right\rbrace \delta_{\mu_{k,j}, \sigma_{k,j}^2} (\cdot), \quad k\in \lbrace 1,2 \rbrace\] <p>where the truncation level $N$ is fixed, $v_{k,j}$ are independent beta random variables for each $j\in \lbrace 1,\ldots, N-1 \rbrace$ with $v_{k,N}=1$, and the atoms $(\mu_{k,j}, \sigma_{k,j}^2)^T$ are independent random vectors distributed according to the base measure $P_{0,k}$. Let $\vec{v}_ k=(v_{k,1}, \ldots, v_{k,N-1})^T$, $\vec{\mu}_ k=(\mu_{k,1}, \ldots, \mu_{k,N})^T$, $\vec{\sigma}_ k ^2=(\sigma_{k,1}^2, \ldots, \sigma_{k,N}^2)^T$, the densities of $G$ and $U$ are</p> \[\begin{aligned} g(x \mid \vec{v}_ 1, \vec{\mu}_ 1, \vec{\sigma}_ 1 ^2) &amp;= \sum_{j=1}^{N} v_{1,j} \left\lbrace \prod_{l=1}^{j-1} (1-v_{1,l}) \right\rbrace \delta_{\mu_{1,j}, \sigma_{1,j}^2} (x) \\ u(x \mid \vec{v}_ 2, \vec{\mu}_ 2, \vec{\sigma}_ 2 ^2) &amp;= \sum_{j=1}^{N} v_{2,j} \left\lbrace \prod_{l=1}^{j-1} (1-v_{2,l}) \right\rbrace \delta_{\mu_{2,j}, \sigma_{2,j}^2} (x) \end{aligned}\] <p>Choosing a spike-and-slab prior that assigns positive probability to the event $\theta=1$ enable us to do model selection, using the posterior probability of $H_0: F=G$, equivalent to $\theta=1$, versus $H_1: F\leq_{LR} G$, equivalent to $\theta\in[0,1)$. Setting $\theta=(1-\gamma)\tilde{\theta}+\gamma$, $H_0: F=G$ and $H_1: F\leq_{LR} G$ can be identified with the events $\gamma=1$ and $\gamma=0$, respectively. The density of $F$ can be expressed as</p> \[f(x \mid \gamma, \tilde{\theta}, \vec{v}_ 1, \vec{\mu}_ 1, \vec{\sigma}_ 1 ^2, \vec{v}_ 2, \vec{\mu}_ 2, \vec{\sigma}_ 2 ^2) = \theta g(x \mid \vec{v}_ 1, \vec{\mu}_ 1, \vec{\sigma}_ 1 ^2) + (1-\theta) \int_{-\infty}^{\infty} g^{s}(x \mid \vec{v}_ 1, \vec{\mu}_ 1, \vec{\sigma}_ 1 ^2)u(s \mid \vec{v}_ 2, \vec{\mu}_ 2, \vec{\sigma}_ 2 ^2)ds\] <p>the joint distribution of the data and parameters is given by</p> \[\begin{aligned} X_i \mid \gamma, \tilde{\theta}, \vec{v}_ 1, \vec{\mu}_ 1, \vec{\sigma}_ 1 ^2, \vec{v}_ 2, \vec{\mu}_ 2, \vec{\sigma}_ 2 ^2 &amp; \stackrel{ind}{\sim} f(\cdot \mid \gamma, \tilde{\theta}, \vec{v}_ 1, \vec{\mu}_ 1, \vec{\sigma}_ 1 ^2, \vec{v}_ 2, \vec{\mu}_ 2, \vec{\sigma}_ 2 ^2), \quad i\in \lbrace 1,\ldots, n \rbrace \\ Y_i \mid \vec{v}_ 1, \vec{\mu}_ 1, \vec{\sigma}_ 1 ^2 &amp; \stackrel{ind}{\sim} g(\cdot \mid \vec{v}_ 1, \vec{\mu}_ 1, \vec{\sigma}_ 1 ^2), \quad i\in \lbrace 1,\ldots, m \rbrace \\ v_{1,j} &amp; \stackrel{ind}{\sim} \mathrm{Beta}(1,\alpha), \quad j\in \lbrace 1,\ldots, N-1 \rbrace \\ (\mu_{1,j}, \sigma_{1,j}^2)^T &amp; \stackrel{ind}{\sim} \mathrm{Normal\space Inv-Gamma}(m,c,a_1,a_2), \quad j\in \lbrace 1,\ldots, N \rbrace \\ \tilde{\theta} \mid \gamma = 0 &amp; \sim \mathrm{Beta}(b_1,b_2) \\ v_{2,j} \mid \gamma = 0 &amp; \stackrel{ind}{\sim} \mathrm{Beta}(1,\alpha), \quad j\in \lbrace 1,\ldots, N-1 \rbrace \\ (\mu_{2,j}, \sigma_{2,j}^2)^T \mid \gamma = 0 &amp; \stackrel{ind}{\sim} \mathrm{Normal\space Inv-Gamma}(m,c,a_1,a_2), \quad j\in \lbrace 1,\ldots, N \rbrace \\ \tilde{\theta} \mid \gamma = 1 &amp; \sim \mathrm{Beta}(\breve{b}_{1},\breve{b}_{2}) \\ v_{2,j} \mid \gamma = 1 &amp; \stackrel{ind}{\sim} \mathrm{Beta}(1,\breve{\alpha}), \quad j\in \lbrace 1,\ldots, N-1 \rbrace \\ (\mu_{2,j}, \sigma_{2,j}^2)^T \mid \gamma = 1 &amp; \stackrel{ind}{\sim} \breve{p}_{2,0}(\cdot), \quad j\in \lbrace 1,\ldots, N \rbrace \\ \gamma &amp; \sim \mathrm{Bernoulli}(p_0) \end{aligned}\] <p>The density of $\mathrm{Normal\space Inv-Gamma}(m,c,a_1,a_2)$ is</p> \[\pi_{\mathrm{NI}}(\mu,\sigma^2 \mid m,c,a_1,a_2) = \frac{\sqrt{c}}{\sigma\sqrt{2\pi}}\frac{a_2^{a_1}}{\Gamma(a_1)}(\frac{1}{\sigma^2})^{a_1+1} \mathrm{exp}(-\frac{2a_2+c(\mu-m)^2}{2\sigma^2})\] <p>The density of $\mathrm{Beta}(b_1,b_2)$ is</p> \[\pi_{\mathrm{Beta}}(v \mid b_1, b_2) = \frac{\Gamma(b_1+b_2)}{\Gamma(b_1)\Gamma(b_2)}v^{b_1-1}(1-v)^{b_2-1}\] <p>The priors for $\tilde{\theta}$, $v_{2,j}$, and $(\mu_{2,j}, \sigma_{2,j}^2)^T$ are defined conditionally on $\gamma$ for computational purposes. The priors given $\gamma = 1$ are <code class="language-plaintext highlighter-rouge">pseudopriors</code>. The full conditional distributions for the slice-within-Gibbs sampler are given, with a dash as shorthand notation,</p> <ol> <li> <p>Update $(\vec{v}_ 1, \vec{\mu}_ 1, \vec{\sigma}_ 1 ^2)^T$.</p> \[\begin{aligned} \pi(\vec{v}_ 1, \vec{\mu}_ 1, \vec{\sigma}_ 1 ^2 \mid \gamma = 0, -) &amp; \propto \left\lbrace \prod_{i=1}^{n} f(X_i \mid \gamma = 0, \tilde{\theta}, \vec{v}_ 1, \vec{\mu}_ 1, \vec{\sigma}_ 1 ^2, \vec{v}_ 2, \vec{\mu}_ 2, \vec{\sigma}_ 2 ^2) \right\rbrace \times \left\lbrace \prod_{i=1}^{m} g(Y_i \mid \vec{v}_ 1, \vec{\mu}_ 1, \vec{\sigma}_ 1 ^2) \right\rbrace \\ &amp; \times \left\lbrace \prod_{j=1}^{N} \pi_{\mathrm{NI}}(\mu_{1,j}, \sigma_{1,j} ^2 \mid m,c,a_1,a_2) \right\rbrace \times \left\lbrace \prod_{j=1}^{N-1} \pi_{\mathrm{Beta}}(v_{1,j} \mid b_1, b_2) \right\rbrace \end{aligned}\] \[\begin{aligned} \pi(\vec{v}_ 1, \vec{\mu}_ 1, \vec{\sigma}_ 1 ^2 \mid \gamma = 1, -) &amp; \propto \left\lbrace \prod_{i=1}^{n} g(X_i \mid \vec{v}_ 1, \vec{\mu}_ 1, \vec{\sigma}_ 1 ^2) \right\rbrace \times \left\lbrace \prod_{i=1}^{m} g(Y_i \mid \vec{v}_ 1, \vec{\mu}_ 1, \vec{\sigma}_ 1 ^2) \right\rbrace \\ &amp; \times \left\lbrace \prod_{j=1}^{N} \pi_{\mathrm{NI}}(\mu_{1,j}, \sigma_{1,j} ^2 \mid m,c,a_1,a_2) \right\rbrace \times \left\lbrace \prod_{j=1}^{N-1} \pi_{\mathrm{Beta}}(v_{1,j} \mid b_1, b_2) \right\rbrace \end{aligned}\] <p>$f(X_i \mid \gamma = 0, \tilde{\theta}, \vec{v}_ 1, \vec{\mu}_ 1, \vec{\sigma}_ 1 ^2, \vec{v}_ 2, \vec{\mu}_ 2, \vec{\sigma}_ 2 ^2)$ is evaluated using numerical integration.</p> </li> <li> <p>Update $(\vec{v}_ 2, \vec{\mu}_ 2, \vec{\sigma}_ 2 ^2)^T$.</p> <p>(1) If $\gamma = 0$, the conditional density</p> \[\begin{aligned} \pi(\vec{v}_ 2, \vec{\mu}_ 2, \vec{\sigma}_ 2 ^2 \mid \gamma = 0, -) &amp; \propto \left\lbrace \prod_{i=1}^{n} f(X_i \mid \gamma = 0, \tilde{\theta}, \vec{v}_ 1, \vec{\mu}_ 1, \vec{\sigma}_ 1 ^2, \vec{v}_ 2, \vec{\mu}_ 2, \vec{\sigma}_ 2 ^2) \right\rbrace \\ &amp; \times \left\lbrace \prod_{j=1}^{N} \pi_{\mathrm{NI}}(\mu_{2,j}, \sigma_{2,j} ^2 \mid m,c,a_1,a_2) \right\rbrace \times \left\lbrace \prod_{j=1}^{N-1} \pi_{\mathrm{Beta}}(v_{2,j} \mid 1,\breve{\alpha}) \right\rbrace \end{aligned}\] <p>(2) If $\gamma = 1$, sample</p> \[\begin{aligned} v_{2,j} \mid \gamma = 1, - &amp; {\sim} \mathrm{Beta}(1,\breve{\alpha}), \quad j\in \lbrace 1,\ldots, N-1 \rbrace \\ (\mu_{2,j}, \sigma_{2,j}^2)^T \mid \gamma = 1, - &amp; {\sim} \breve{p}_{2,0}(\cdot), \quad j\in \lbrace 1,\ldots, N \rbrace \end{aligned}\] </li> <li> <p>Update $\tilde{\theta}$. For each $i \in \lbrace 1,\ldots,n \rbrace$, a latent variable $R_i$ that associates $X_i$ with one of the two components in the mixture representation is introduced,</p> \[\begin{aligned} X_i \mid R_i = 1, \gamma \in \lbrace 0,1 \rbrace, - &amp; \sim g(\cdot \mid \vec{v}_ 1, \vec{\mu}_ 1, \vec{\sigma}_ 1 ^2) \\ X_i \mid R_i = 0, \gamma = 0, - &amp; \sim \int_{-\infty}^{\infty} g^{s}(\cdot \mid \vec{v}_ 1, \vec{\mu}_ 1, \vec{\sigma}_ 1 ^2)u(s \mid \vec{v}_ 2, \vec{\mu}_ 2, \vec{\sigma}_ 2 ^2)ds \\ R_i \mid \gamma = 0 &amp; \sim \mathrm{Bernoulli}(\tilde{\theta}) \\ \tilde{\theta} \mid \gamma = 0 &amp; \sim \mathrm{Beta}(b_1,b_2) \\ R_i \mid \gamma = 1 &amp; \sim \delta_1(\cdot) \\ \tilde{\theta} \mid \gamma = 1 &amp; \sim \mathrm{Beta}(\breve{b}_1,\breve{b}_2) \end{aligned}\] <p>As $\mathrm{Pr}(R_i = 0, \gamma = 1) = 0$, $R_i$ is updated with</p> \[\begin{aligned} \mathrm{Pr}(R_i = 1 \mid \gamma = 0, -) &amp;= \frac{\tilde{\theta}g(X_i \mid \vec{v}_ 1, \vec{\mu}_ 1, \vec{\sigma}_ 1 ^2)}{\tilde{\theta}g(X_i \mid \vec{v}_ 1, \vec{\mu}_ 1, \vec{\sigma}_ 1 ^2) + (1- \tilde{\theta})\int_{-\infty}^{\infty} g^{s}(X_i \mid \vec{v}_ 1, \vec{\mu}_ 1, \vec{\sigma}_ 1 ^2)u(s \mid \vec{v}_ 2, \vec{\mu}_ 2, \vec{\sigma}_ 2 ^2)ds}\\ \mathrm{Pr}(R_i = 0 \mid \gamma = 0, -) &amp;= 1-\mathrm{Pr}(R_i = 1 \mid \gamma = 0, -)\\ \mathrm{Pr}(R_i = 1 \mid \gamma = 1, -) &amp;= 1 \end{aligned}\] <p>and $\tilde{\theta}$ is updated with</p> \[\begin{aligned} \tilde{\theta} \mid \gamma = 0, - &amp; \sim \mathrm{Beta}(b_1+\sum_{i=1}^{n}R_i, b_2+n-\sum_{i=1}^{n}R_i) \\ \tilde{\theta} \mid \gamma = 1, - &amp; \sim \mathrm{Beta}(\breve{b}_1,\breve{b}_2) \end{aligned}\] </li> <li> <p>Update $\gamma$. The full conditional distribution for $\gamma$ is Bernoulli with</p> \[\begin{aligned} \mathrm{Pr}(\gamma = 0 \mid -) &amp; = \frac{(1-p_0) \prod_{i=1}^{n} f(X_i \mid \gamma = 0, \tilde{\theta}, \vec{v}_ 1, \vec{\mu}_ 1, \vec{\sigma}_ 1 ^2, \vec{v}_ 2, \vec{\mu}_ 2, \vec{\sigma}_ 2 ^2)}{\mathnormal{Z}_ {\gamma}}\\ \mathrm{Pr}(\gamma = 1 \mid -) &amp; = \frac{p_0 \prod_{i=1}^{n} g(X_i \mid \vec{v}_ 1, \vec{\mu}_ 1, \vec{\sigma}_ 1 ^2)}{\mathnormal{Z}_ {\gamma}}\\ \end{aligned}\] <p>where</p> \[\mathnormal{Z}_ {\gamma} = p_0 \prod_{i=1}^{n} g(X_i \mid \vec{v}_ 1, \vec{\mu}_ 1, \vec{\sigma}_ 1 ^2) + (1-p_0) \prod_{i=1}^{n} f(X_i \mid \gamma = 0, \tilde{\theta}, \vec{v}_ 1, \vec{\mu}_ 1, \vec{\sigma}_ 1 ^2, \vec{v}_ 2, \vec{\mu}_ 2, \vec{\sigma}_ 2 ^2)\] </li> </ol> <p><code class="language-plaintext highlighter-rouge">pseudopriors</code> (conditional on $\gamma = 1$) $\mathrm{Beta}(\breve{b}_ 1, \breve{b}_ 2)$, $\mathrm{Beta}(1,\breve{\alpha})$ and $\breve{p}_ {2,0}(\cdot)$ are defined to resemble the posterior distribution of $\tilde{\theta}$, $\vec{v}_ 2$, and $(\vec{\mu}_ 2, \vec{\sigma}_ 2 ^2)^T$ conditional on $\gamma = 0$. First, fix $\gamma = 0$ and run first three steps in a sampler for $Q$ iterations, the Markov chain output $(\tilde{\theta}_ {(1)}, \vec{v}_ {2,(1)}, \vec{\mu}_ {2,(1)}, \vec{\sigma}_ {2,(1)} ^2)^T, \ldots, (\tilde{\theta}_ {(Q)}, \vec{v}_ {2,(Q)}, \vec{\mu}_ {2,(Q)}, \vec{\sigma}_ {2,(Q)} ^2)^T$ provides an approximation of the posterior distribution of $\tilde{\theta}$, $\vec{v}_ 2$, and $(\vec{\mu}_ 2, \vec{\sigma}_ 2 ^2)^T$ conditional on $\gamma = 0$. Then we use the Markvo chain output to determine the <code class="language-plaintext highlighter-rouge">pseudopriors</code>.</p> <p>For the <code class="language-plaintext highlighter-rouge">pseudopriors</code> of $\tilde{\theta}$,</p> \[(\breve{b}_ 1, \breve{b}_ 2) = \arg\max_ {(a,b)} \prod_{q=1}^{Q} \pi_{\mathrm{Beta}}(\tilde{\theta}_{(q)} \mid a, b)\] <p>For the <code class="language-plaintext highlighter-rouge">pseudopriors</code> of $\vec{v}_ 2$,</p> \[\breve{\alpha} = \frac{1}{Q}\sum_{q=1}^{Q} \arg\max _ {a} \prod_{j=1}^{N-1} \pi_{\mathrm{Beta}}(v_{2,j(q)} \mid 1, a)\] <p>For the <code class="language-plaintext highlighter-rouge">pseudopriors</code> of $(\vec{\mu}_ 2, \vec{\sigma}_ 2 ^2)^T$, $\breve{p}_ {2,0}(\cdot)$ is set as a kernel density estimate using the function $\it{kde}$ in the $\bold{R}$ package $\it{ks}$ computed from $(m_1,s_1^2)^T, \ldots, (m_Q,s_Q^2)^T$, where</p> \[(m_q,s_q^2) \sim u_{(q)}(\cdot \mid \vec{v}_ 2, \vec{\mu}_ 2, \vec{\sigma}_ 2 ^2) = \sum_{j=1}^{N} v_{2,j(q)} \left\lbrace \prod_{l=1}^{j-1} (1-v_{2,l(q)}) \right\rbrace \delta_{\mu_{2,j(q)}, \sigma_{2,j(q)}^2} (\cdot)\] <h3 id="in-project">In project</h3> <p>To test the correlation between different components in different simplexes is equivalent to do model selection between these two models:</p> <ol> <li> <p>Dependent simplexes:</p> </li> <li> <p>Independent simplexes:</p> </li> </ol> <hr/>]]></content><author><name></name></author><category term="Bayesian-model/variable-selection"/><summary type="html"><![CDATA[Bayesian model selection]]></summary></entry><entry><title type="html">Identifiability</title><link href="https://rufeng-liu.github.io/blog/2023/Identifiability/" rel="alternate" type="text/html" title="Identifiability"/><published>2023-11-01T00:00:00+00:00</published><updated>2023-11-01T00:00:00+00:00</updated><id>https://rufeng-liu.github.io/blog/2023/Identifiability</id><content type="html" xml:base="https://rufeng-liu.github.io/blog/2023/Identifiability/"><![CDATA[<h2 id="definition">Definition</h2> <hr/> <h2 id="examples">Examples</h2> <hr/>]]></content><author><name></name></author><category term="Identifiability"/><summary type="html"><![CDATA[Identifiability]]></summary></entry><entry><title type="html">Spline</title><link href="https://rufeng-liu.github.io/blog/2023/Spline/" rel="alternate" type="text/html" title="Spline"/><published>2023-10-01T00:00:00+00:00</published><updated>2023-10-01T00:00:00+00:00</updated><id>https://rufeng-liu.github.io/blog/2023/Spline</id><content type="html" xml:base="https://rufeng-liu.github.io/blog/2023/Spline/"><![CDATA[<h2 id="preview">Preview</h2> <h3 id="runges-phenomenon">Runge’s phenomenon</h3> <h3 id="gibbs-phenomenon">Gibbs phenomenon</h3> <hr/> <h2 id="definition">Definition</h2> <hr/>]]></content><author><name></name></author><category term="Spline"/><summary type="html"><![CDATA[Spline]]></summary></entry><entry><title type="html">Scalability</title><link href="https://rufeng-liu.github.io/blog/2023/Scalability/" rel="alternate" type="text/html" title="Scalability"/><published>2023-09-01T00:00:00+00:00</published><updated>2023-09-01T00:00:00+00:00</updated><id>https://rufeng-liu.github.io/blog/2023/Scalability</id><content type="html" xml:base="https://rufeng-liu.github.io/blog/2023/Scalability/"><![CDATA[<h2 id="definition">Definition</h2> <hr/> <h2 id="examples">Examples</h2> <hr/>]]></content><author><name></name></author><category term="Scalability"/><summary type="html"><![CDATA[Scalability]]></summary></entry><entry><title type="html">Convergence rate for Bayesian mixtures through examples</title><link href="https://rufeng-liu.github.io/blog/2023/Convergence-rate-for-Bayesian-mixtures-through-examples/" rel="alternate" type="text/html" title="Convergence rate for Bayesian mixtures through examples"/><published>2023-08-15T00:00:00+00:00</published><updated>2023-08-15T00:00:00+00:00</updated><id>https://rufeng-liu.github.io/blog/2023/Convergence-rate-for-Bayesian-mixtures-through-examples</id><content type="html" xml:base="https://rufeng-liu.github.io/blog/2023/Convergence-rate-for-Bayesian-mixtures-through-examples/"><![CDATA[<h2 id="definition">Definition</h2> <hr/> <h2 id="examples">Examples</h2> <hr/>]]></content><author><name></name></author><category term="Convergence"/><category term="rate"/><summary type="html"><![CDATA[Convergence rate]]></summary></entry></feed>